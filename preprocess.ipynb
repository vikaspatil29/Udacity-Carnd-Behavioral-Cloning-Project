{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data imported starts here \n",
      "data size is: 438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 26.47items/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features size 300\n",
      "features shape (300, 18, 80, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 39964.78items/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: (300, 18, 80, 1)\n",
      "labels: (300,)\n",
      "train size: 202\n",
      "valid size: 68\n",
      "test size: 30\n",
      "input_shape: (18, 80, 1)\n",
      "features count: 1440\n",
      "Saving data to pickle file...\n",
      "Data cached in pickle file.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This python script will preprocess the data images.\n",
    "It will import the images from center, left, and right camera\n",
    "and turn it into numpy arrays. These numpy arrays will be splitted\n",
    "into train and validation sets and saved as pickle.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import base64\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "### Paths to folder and label\n",
    "folder_path = \"C:/Users/vikas/Desktop/behaviourial_cloning/training_data\"\n",
    "label_path = \"{}/driving_log.csv\".format(folder_path)\n",
    "\n",
    "\n",
    "### Import data\n",
    "data = []\n",
    "with open(label_path) as F:\n",
    "    reader = csv.reader(F)\n",
    "    for i in reader:\n",
    "        data.append(i) \n",
    "\n",
    "print(\"data imported starts here \")\n",
    "\n",
    "### size of the data\n",
    "data_size = len(data)\n",
    "print(\"data size is:\", data_size)\n",
    "\n",
    "### Emtpy generators for feature and labels\n",
    "features = ()\n",
    "labels = ()\n",
    "\n",
    "### This function will resize the images from front, left and\n",
    "### right camera to 18 x 80 and turn them into lists.\n",
    "### The length of the each list will be 18 x 80 = 1440\n",
    "### j = 0,1,2 corresponds to center, left, right\n",
    "def load_image(data_line, j):\n",
    "    img = plt.imread(data_line[j].strip())[65:135:4,0:-1:4,0]\n",
    "    lis = img.flatten().tolist()\n",
    "    return lis\n",
    "\n",
    "data = data[:100]\n",
    "\n",
    "# For each item in data, convert camera images to single list\n",
    "# and save them into features list.\n",
    "for i in tqdm(range(int(len(data))), unit='items'):\n",
    "    for j in range(3):\n",
    "        features += (load_image(data[i],j),)\n",
    "\n",
    "item_num = len(features)\n",
    "print(\"features size\", item_num)\n",
    "\n",
    "# A single list will be convert back to the original image shapes.\n",
    "# Each list contains 3 images so the shape of the result will be\n",
    "# 54 x 80 where 3 images aligned vertically.\n",
    "features = np.array(features).reshape(item_num, 18, 80, 1)\n",
    "print(\"features shape\", features.shape)\n",
    "\n",
    "### Save labels    \n",
    "for i in tqdm(range(int(len(data))), unit='items'):\n",
    "    for j in range(3):\n",
    "        labels += (float(data[i][3]),)\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"features:\", features.shape)\n",
    "print(\"labels:\", labels.shape)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Get randomized datasets for training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.10,\n",
    "    random_state=832289)\n",
    "\n",
    "# Get randomized datasets for training and validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.25,\n",
    "    random_state=832289)\n",
    "\n",
    "# Print out shapes of new arrays\n",
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "valid_size = X_valid.shape[0]\n",
    "input_shape = X_train.shape[1:]\n",
    "features_count = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n",
    "\n",
    "print(\"train size:\", train_size)\n",
    "print(\"valid size:\", valid_size)\n",
    "print(\"test size:\", test_size)\n",
    "print(\"input_shape:\", input_shape)\n",
    "print(\"features count:\", features_count)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save the data for easy access\n",
    "pickle_file = 'C:/Users/vikas/Desktop/behaviourial_cloning/examples/carnd.pickle'\n",
    "stop = False\n",
    "\n",
    "while not stop:\n",
    "    if not os.path.isfile(pickle_file):\n",
    "        print('Saving data to pickle file...')\n",
    "        try:\n",
    "            with open(pickle_file, 'wb') as pfile:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        'train_dataset': X_train,\n",
    "                        'train_labels': y_train,\n",
    "                        'valid_dataset': X_valid,\n",
    "                        'valid_labels': y_valid,\n",
    "                        'test_dataset': X_test,\n",
    "                        'test_labels': y_test,\n",
    "                    },\n",
    "                    pfile, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to', pickle_file, ':', e)\n",
    "            raise\n",
    "\n",
    "        print('Data cached in pickle file.')\n",
    "        stop = True\n",
    "    else:\n",
    "        print(\"Please use a different file name other than carnd.pickle\")\n",
    "        pickle_file = input(\"Enter: \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
